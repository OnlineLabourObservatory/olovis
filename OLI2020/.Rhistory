df <- data.frame(matrix(ncol = 3, nrow = 0))
x <- c("date", "worker", "occupation")
colnames(df) <- x
for (i in unique(worker_data$occupation)) {
df_temp <- worker_data %>% filter(occupation == i & country == "Serbia")
df_temp <- df_temp %>% mutate(worker = rollmean(df_temp$num_workers/df_temp$num_workers[df_temp$date == "2019-01-01"]*100, 28, fill = list(NA, NULL, NA), align = "right"))
df_temp$worker <- ifelse(is.na(df_temp$worker), df_temp$worker, df_temp$worker)
df_temp <- subset(df_temp, date>="2020-01-01" & date<="2020-09-22")
df_temp <- df_temp %>% mutate(worker = df_temp$worker/df_temp$worker[df_temp$date == "2020-01-01"]*100)
df_temp <- df_temp[,c("date","worker","occupation")]
df <- rbind(df,df_temp)
}
df$occupation[df$occupation=="Software development and technology"] <-  "Software development and tech"
ggplot(df, aes(x = as.Date(date), y = worker)) +
geom_line(aes(color=occupation), size = 3) +
scale_color_manual(values = cls) +
labs(y="Registered workers in Serbia (100 = February 1st)",x="2020", caption = "Source: Online Labour Index - ilabour.oii.ox.ac.uk") +
theme_minimal() + theme(axis.text=element_text(size=20), axis.title = element_text(size=20),
legend.text =element_text(size=20), legend.title =element_text(size=20),
legend.position="bottom") + theme(legend.title=element_blank())
worker_data$date <- as.Date(worker_data$timestamp, format = "%Y-%M-%D")
worker_data$month <- cut(worker_data$date, breaks = "months")
df <- data.frame(matrix(ncol = 3, nrow = 0))
x <- c("date", "worker", "occupation")
colnames(df) <- x
for (i in unique(worker_data$occupation)) {
df_temp <- worker_data %>% filter(occupation == i & country == "Serbia")
df_temp <- df_temp %>% mutate(worker = rollmean(df_temp$num_workers/df_temp$num_workers[df_temp$date == "2020-01-01"]*100, 28, fill = list(NA, NULL, NA), align = "right"))
df_temp$worker <- ifelse(is.na(df_temp$worker), df_temp$worker, df_temp$worker)
df_temp <- subset(df_temp, date>="2020-01-01" & date<="2020-09-22")
#df_temp <- df_temp %>% mutate(worker = df_temp$worker/df_temp$worker[df_temp$date == "2020-01-01"]*100)
df_temp <- df_temp[,c("date","worker","occupation")]
df <- rbind(df,df_temp)
}
df$occupation[df$occupation=="Software development and technology"] <-  "Software development and tech"
ggplot(df, aes(x = as.Date(date), y = worker)) +
geom_line(aes(color=occupation), size = 3) +
scale_color_manual(values = cls) +
labs(y="Registered workers in Serbia (100 = February 1st)",x="2020", caption = "Source: Online Labour Index - ilabour.oii.ox.ac.uk") +
theme_minimal() + theme(axis.text=element_text(size=20), axis.title = element_text(size=20),
legend.text =element_text(size=20), legend.title =element_text(size=20),
legend.position="bottom") + theme(legend.title=element_blank())
worker_data$date <- as.Date(worker_data$timestamp, format = "%Y-%M-%D")
worker_data$month <- cut(worker_data$date, breaks = "months")
df <- data.frame(matrix(ncol = 3, nrow = 0))
x <- c("date", "worker", "occupation")
colnames(df) <- x
for (i in unique(worker_data$occupation)) {
df_temp <- worker_data %>% filter(occupation == i & country == "Serbia")
df_temp <- df_temp %>% mutate(worker = rollmean(df_temp$num_workers/df_temp$num_workers[df_temp$date == "2020-01-01"]*100, 28, fill = list(NA, NULL, NA), align = "right"))
df_temp$worker <- ifelse(is.na(df_temp$worker), df_temp$worker, df_temp$worker)
df_temp <- subset(df_temp, date>="2020-01-01" & date<="2020-09-22")
df_temp <- df_temp %>% mutate(worker = df_temp$worker/df_temp$worker[df_temp$date == "2020-01-01"]*100)
df_temp <- df_temp[,c("date","worker","occupation")]
df <- rbind(df,df_temp)
}
df$occupation[df$occupation=="Software development and technology"] <-  "Software development and tech"
ggplot(df, aes(x = as.Date(date), y = worker)) +
geom_line(aes(color=occupation), size = 3) +
scale_color_manual(values = cls) +
labs(y="Registered workers in Serbia (100 = February 1st)",x="2020", caption = "Source: Online Labour Index - ilabour.oii.ox.ac.uk") +
theme_minimal() + theme(axis.text=element_text(size=20), axis.title = element_text(size=20),
legend.text =element_text(size=20), legend.title =element_text(size=20),
legend.position="bottom") + theme(legend.title=element_blank())
write_csv(df,"/Users/fabian/Desktop/supply_serbia_occupations.csv")
setwd("~/Fabian GDrive/Projects/Research Projects/Crowdlearn Surveys")
##############################
## Anoush's Survey Analysis
##############################
## Read packages
library(dplyr)        # Modify DFs
library(readxl)        # Modify DFs
##############################
# Analyse Surveys on Workers
## Get files
s1 <- read_excel("CLP_AMT-Survey1-LargeSample.xlsx")
s2 <- read_excel("CLP_AMT-Survey2-SmallerSample.xlsx")
s3 <- read_excel("CL_OF-Survey.xlsx")
## Keep relevant vars
s1 <- s1 %>% dplyr::select(wid,NW1,NW2,NW3,NW4,NW5,NW6,NW7,NW8,NW9,NW10,NW11,NW12,NW13,NW14,NW15,
"Information Finding","Interpretation and Analysis", "Survey", "Verification and Validation",
"Content Creation", "Content Access")
s2 <- s2 %>% dplyr::select(wid,NW1,NW2,NW3,NW4,NW5,NW6,NW7,NW8,NW9,NW10,NW11,NW12,NW13,NW14,NW15,
"Survey","Interpretation_and_Analysis","Verification_and_Validation",
"Content_Access","Content_Creation","Information_Finding")
s3 <- s3 %>% dplyr::select(wid,NW1,NW2,NW3,NW4,NW5,NW6,NW7,NW8,NW9,NW10,NW11,NW12,NW13,NW14,NW15)
## Relabel vars for rbinding
colnames(s2) <- str_replace(str_replace(colnames(s2),"_"," "),"_"," ")
##############################
# Work with AMT surveys
## Rbind suerveys on AMT workers
df <- rbind(s1,s2)
round(colMeans(df[,2:16]),2)
## Create string of question combinations
for (i in 2:16) {
df[i] <- ifelse(df[i] == 1, colnames(df[i]), "")
}
df$combo <- apply(df[,2:16], 1, paste, collapse="")
## Summarize frequency of combinations across item size
df_stats <- df %>% group_by(combo) %>% dplyr::mutate(items = str_count(combo,"NW"), n = n()) %>% group_by(items) %>% dplyr::mutate(m = n()) %>%
group_by(items,combo) %>% dplyr::summarise(item_count = m, combo_count = n(), combo_share = round(n/length(df$wid)*100,2), group_share = round(n/m*100,2))
## Drop duplicates
df_stats <- df_stats[!duplicated(df_stats),]
write.csv(df_stats, "amt_survey_question_summary.csv", row.names=FALSE)
##############################
# Produce item combo heatmap for AMT workers
## Read data
df_heat <- rbind(s1,s2) %>% dplyr::select(wid,NW1,NW2,NW3,NW4,NW5,NW6,NW7,NW8,NW9,NW10,NW11,NW12,NW13,NW14,NW15)
## Create adjacency list
df_heat <- melt(df_heat)
df_from <- df_heat %>% filter(value == 1) %>% dplyr::select(wid,variable)
names(df_from) <- c("id","from")
df_to <- df_from
names(df_to) <- c("id","to")
## Merge long list with itself to get adjacency list
adj_list <- left_join(df_from,df_to)
adj_list <- adj_list %>% filter(from != to) %>% group_by(from, to) %>% dplyr::summarise(n = n())
## Plot Heatmap
ggplot(adj_list, aes(from, to)) +
geom_tile(aes(fill = n)) +
geom_text(aes(label = round(n, 1))) + labs(y = "", x = "", title = "Type of Task - Co-Occurance Matrix", subtitle = "AMT Worker Surveys") +
scale_fill_gradient(low = "white", high = "red") + theme_classic()
##############################
# Work with Survey 3 - Freelancers
df <- s3
round(colMeans(df[,2:16]),2)
## Create string of question combinations
round(colMeans(df[,2:16]),2)
for (i in 2:16) {
df[i] <- ifelse(df[i] == 1, colnames(df[i]), "")
}
df$combo <- apply(df[,2:16], 1, paste, collapse="")
## Summarize frequency of combinations across item size
df_stats <- df %>% group_by(combo) %>% dplyr::mutate(items = str_count(combo,"NW"), n = n()) %>% group_by(items) %>% dplyr::mutate(m = n()) %>%
group_by(items,combo) %>% dplyr::summarise(item_count = m, combo_count = n(), combo_share = round(n/length(df$wid)*100,2), group_share = round(n/m*100,2))
## Drop duplicates
df_stats <- df_stats[!duplicated(df_stats),]
write.csv(df_stats, "of_survey_question_summary.csv", row.names=FALSE)
##############################
# Produce item combo heatmap for Freelancers
## Read data
df_heat <- s3 %>% dplyr::select(wid,NW1,NW2,NW3,NW4,NW5,NW6,NW7,NW8,NW9,NW10,NW11,NW12,NW13,NW14,NW15)
## Create adjacency list
df_heat <- melt(df_heat)
df_from <- df_heat %>% filter(value == 1) %>% dplyr::select(wid,variable)
names(df_from) <- c("id","from")
df_to <- df_from
names(df_to) <- c("id","to")
## Merge long list with itself to get adjacency list
adj_list <- left_join(df_from,df_to)
adj_list <- adj_list %>% filter(from != to) %>% group_by(from, to) %>% dplyr::summarise(n = n())
## Plot Heatmap
ggplot(adj_list, aes(from, to)) +
geom_tile(aes(fill = n)) +
geom_text(aes(label = round(n, 1))) + labs(y = "", x = "", title = "Type of Task - Co-Occurance Matrix", subtitle = "Freelancer Surveys") +
scale_fill_gradient(low = "white", high = "blue") + theme_classic()
##############################
# Freelancer Surveys: Analyse Tasks and NW
df <- rbind(s1,s2)
a <- df %>% filter(NW1==1 | NW14==1) %>%
dplyr::summarise(`Information Finding` = round(mean(`Information Finding`),3),
`Interpretation and Analysis` = round(mean(`Interpretation and Analysis`),3),
`Survey` = round(mean(`Survey`),3),
`Verification and Validation` = round(mean(`Verification and Validation`),3),
`Content Creation` = round(mean(`Content Creation`),3),
`Content Access` = round(mean(`Content Access`),3),
Category = "NW1 or NW14"
)
b <- df %>% filter(NW6 == 1 | NW7 == 1 | NW8 == 1 | NW9 == 1 | NW10 == 1 | NW11 == 1 |
NW12 == 1 | NW13 == 1 | NW14 == 1 | NW15 == 1) %>%
dplyr::summarise(`Information Finding` = round(mean(`Information Finding`),3),
`Interpretation and Analysis` = round(mean(`Interpretation and Analysis`),3),
`Survey` = round(mean(`Survey`),3),
`Verification and Validation` = round(mean(`Verification and Validation`),3),
`Content Creation` = round(mean(`Content Creation`),3),
`Content Access` = round(mean(`Content Access`),3),
Category = "NW6-NW15"
)
df_stats <- rbind(a,b)
df_stats
##############################
## Anoush's Survey Analysis
##############################
## Read packages
library(dplyr)        # Modify DFs
library(readxl)        # Modify DFs
##############################
# Analyse Surveys on Workers
## Get files
s1 <- read_excel("CLP_AMT-Survey1-LargeSample.xlsx")
s2 <- read_excel("CLP_AMT-Survey2-SmallerSample.xlsx")
s3 <- read_excel("CL_OF-Survey.xlsx")
## Keep relevant vars
s1 <- s1 %>% dplyr::select(wid,NW1,NW2,NW3,NW4,NW5,NW6,NW7,NW8,NW9,NW10,NW11,NW12,NW13,NW14,NW15,
"Information Finding","Interpretation and Analysis", "Survey", "Verification and Validation",
"Content Creation", "Content Access")
s2 <- s2 %>% dplyr::select(wid,NW1,NW2,NW3,NW4,NW5,NW6,NW7,NW8,NW9,NW10,NW11,NW12,NW13,NW14,NW15,
"Survey","Interpretation_and_Analysis","Verification_and_Validation",
"Content_Access","Content_Creation","Information_Finding")
s3 <- s3 %>% dplyr::select(wid,NW1,NW2,NW3,NW4,NW5,NW6,NW7,NW8,NW9,NW10,NW11,NW12,NW13,NW14,NW15)
## Relabel vars for rbinding
colnames(s2) <- str_replace(str_replace(colnames(s2),"_"," "),"_"," ")
library(stringr)      # Mutate strings
##############################
# Analyse Surveys on Workers
## Get files
s1 <- read_excel("CLP_AMT-Survey1-LargeSample.xlsx")
s2 <- read_excel("CLP_AMT-Survey2-SmallerSample.xlsx")
s3 <- read_excel("CL_OF-Survey.xlsx")
## Keep relevant vars
s1 <- s1 %>% dplyr::select(wid,NW1,NW2,NW3,NW4,NW5,NW6,NW7,NW8,NW9,NW10,NW11,NW12,NW13,NW14,NW15,
"Information Finding","Interpretation and Analysis", "Survey", "Verification and Validation",
"Content Creation", "Content Access")
s2 <- s2 %>% dplyr::select(wid,NW1,NW2,NW3,NW4,NW5,NW6,NW7,NW8,NW9,NW10,NW11,NW12,NW13,NW14,NW15,
"Survey","Interpretation_and_Analysis","Verification_and_Validation",
"Content_Access","Content_Creation","Information_Finding")
s3 <- s3 %>% dplyr::select(wid,NW1,NW2,NW3,NW4,NW5,NW6,NW7,NW8,NW9,NW10,NW11,NW12,NW13,NW14,NW15)
## Relabel vars for rbinding
colnames(s2) <- str_replace(str_replace(colnames(s2),"_"," "),"_"," ")
##############################
# Work with AMT surveys
## Rbind suerveys on AMT workers
df <- rbind(s1,s2)
round(colMeans(df[,2:16]),2)
##############################
# Work with AMT surveys
## Rbind suerveys on AMT workers
df <- rbind(s1,s2)
round(colMeans(df[,2:16]),2)
## Create string of question combinations
for (i in 2:16) {
df[i] <- ifelse(df[i] == 1, colnames(df[i]), "")
}
df$combo <- apply(df[,2:16], 1, paste, collapse="")
## Summarize frequency of combinations across item size
df_stats <- df %>% group_by(combo) %>% dplyr::mutate(items = str_count(combo,"NW"), n = n()) %>% group_by(items) %>% dplyr::mutate(m = n()) %>%
group_by(items,combo) %>% dplyr::summarise(item_count = m, combo_count = n(), combo_share = round(n/length(df$wid)*100,2), group_share = round(n/m*100,2))
## Drop duplicates
df_stats <- df_stats[!duplicated(df_stats),]
write.csv(df_stats, "amt_survey_question_summary.csv", row.names=FALSE)
##############################
# Produce item combo heatmap for AMT workers
## Read data
df_heat <- rbind(s1,s2) %>% dplyr::select(wid,NW1,NW2,NW3,NW4,NW5,NW6,NW7,NW8,NW9,NW10,NW11,NW12,NW13,NW14,NW15)
## Create adjacency list
df_heat <- melt(df_heat)
df_from <- df_heat %>% filter(value == 1) %>% dplyr::select(wid,variable)
names(df_from) <- c("id","from")
df_to <- df_from
library(reshape2)     # Melt tables
##############################
# Freelancer Surveys: Analyse Tasks and NW
df <- rbind(s1,s2)
a <- df %>% filter(NW1==1 | NW14==1) %>%
dplyr::summarise(`Information Finding` = round(mean(`Information Finding`),3),
`Interpretation and Analysis` = round(mean(`Interpretation and Analysis`),3),
`Survey` = round(mean(`Survey`),3),
`Verification and Validation` = round(mean(`Verification and Validation`),3),
`Content Creation` = round(mean(`Content Creation`),3),
`Content Access` = round(mean(`Content Access`),3),
Category = "NW1 or NW14"
)
b <- df %>% filter(NW6 == 1 | NW7 == 1 | NW8 == 1 | NW9 == 1 | NW10 == 1 | NW11 == 1 |
NW12 == 1 | NW13 == 1 | NW14 == 1 | NW15 == 1) %>%
dplyr::summarise(`Information Finding` = round(mean(`Information Finding`),3),
`Interpretation and Analysis` = round(mean(`Interpretation and Analysis`),3),
`Survey` = round(mean(`Survey`),3),
`Verification and Validation` = round(mean(`Verification and Validation`),3),
`Content Creation` = round(mean(`Content Creation`),3),
`Content Access` = round(mean(`Content Access`),3),
Category = "NW6-NW15"
)
df_stats <- rbind(a,b)
df_stats
a <- df %>% filter(NW1==1) %>%
dplyr::summarise(`Information Finding` = round(mean(`Information Finding`),3),
`Interpretation and Analysis` = round(mean(`Interpretation and Analysis`),3),
`Survey` = round(mean(`Survey`),3),
`Verification and Validation` = round(mean(`Verification and Validation`),3),
`Content Creation` = round(mean(`Content Creation`),3),
`Content Access` = round(mean(`Content Access`),3),
Category = "NW1 or NW14"
)
b <- df %>% filter(NW1==1 | NW14==1) %>%
dplyr::summarise(`Information Finding` = round(mean(`Information Finding`),3),
`Interpretation and Analysis` = round(mean(`Interpretation and Analysis`),3),
`Survey` = round(mean(`Survey`),3),
`Verification and Validation` = round(mean(`Verification and Validation`),3),
`Content Creation` = round(mean(`Content Creation`),3),
`Content Access` = round(mean(`Content Access`),3),
Category = "NW1 or NW14"
)
c <- df %>% filter(NW6 == 1 | NW7 == 1 | NW8 == 1 | NW9 == 1 | NW10 == 1 | NW11 == 1 |
NW12 == 1 | NW13 == 1 | NW14 == 1 | NW15 == 1) %>%
dplyr::summarise(`Information Finding` = round(mean(`Information Finding`),3),
`Interpretation and Analysis` = round(mean(`Interpretation and Analysis`),3),
`Survey` = round(mean(`Survey`),3),
`Verification and Validation` = round(mean(`Verification and Validation`),3),
`Content Creation` = round(mean(`Content Creation`),3),
`Content Access` = round(mean(`Content Access`),3),
Category = "NW6-NW15"
)
df_stats <- rbind(a,b,c)
df_stats
a <- df %>% filter(NW1==1) %>%
dplyr::summarise(`Information Finding` = round(mean(`Information Finding`),3),
`Interpretation and Analysis` = round(mean(`Interpretation and Analysis`),3),
`Survey` = round(mean(`Survey`),3),
`Verification and Validation` = round(mean(`Verification and Validation`),3),
`Content Creation` = round(mean(`Content Creation`),3),
`Content Access` = round(mean(`Content Access`),3),
Category = "NW1"
)
b <- df %>% filter(NW1==1 | NW14==1) %>%
dplyr::summarise(`Information Finding` = round(mean(`Information Finding`),3),
`Interpretation and Analysis` = round(mean(`Interpretation and Analysis`),3),
`Survey` = round(mean(`Survey`),3),
`Verification and Validation` = round(mean(`Verification and Validation`),3),
`Content Creation` = round(mean(`Content Creation`),3),
`Content Access` = round(mean(`Content Access`),3),
Category = "NW1 or NW14"
)
c <- df %>% filter(NW6 == 1 | NW7 == 1 | NW8 == 1 | NW9 == 1 | NW10 == 1 | NW11 == 1 |
NW12 == 1 | NW13 == 1 | NW14 == 1 | NW15 == 1) %>%
dplyr::summarise(`Information Finding` = round(mean(`Information Finding`),3),
`Interpretation and Analysis` = round(mean(`Interpretation and Analysis`),3),
`Survey` = round(mean(`Survey`),3),
`Verification and Validation` = round(mean(`Verification and Validation`),3),
`Content Creation` = round(mean(`Content Creation`),3),
`Content Access` = round(mean(`Content Access`),3),
Category = "NW6-NW15"
)
df_stats <- rbind(a,b,c)
df_stats
View(a)
df %>% filter(NW1==1)
a <- df %>% filter(NW1==1)
View(a)
setwd("~/Fabian GDrive/Projects/Other Projects/2021-02 HIIG AI workforce")
#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%
# Cross-Skilling Analysis of UpWork Data #
# 23-09-2020 | Fabian Stephany | fabian.stephany@oii.ox.ac.uk #
#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%
#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%
## Material
# https://www.r-project.org/nosvn/pandoc/gender.html
# https://www.upwork.com/search/profiles/?pt=independent
# https://stats.idre.ucla.edu/r/seminars/interactions-r/
# http://www.sthda.com/english/articles/32-r-graphics-essentials/132-plot-grouped-data-box-plot-bar-plot-and-more/
##################################################################
## Read packages and define functions
##################################################################
library(dplyr)        # Modify DFs
library(tidyr)        # Modify DFs
library(ggplot2)      # GGplot
library(jsonlite)     # Read JSON files
library(stringr)      # Modify strings
library(gender)       # Identify gender by first  name
library(ggbeeswarm)   # GGplot Beeswarm
library(ggridges)     # GGPlot Ridges
library(ggpubr)       # Arrange plots
library(stargazer)    # Show regression tables
library(devtools)     # Special toolkit
install_github("dgrtwo/broom") # Export regression tables to csv
library(broom) # Export regression tables to csv
library("ggwordcloud") # Build wordclouds
theme_set(theme_ridges())
data_summary <- function(x) {
m <- mean(x)
ymin <- m-sd(x)
ymax <- m+sd(x)
return(c(y=m,ymin=ymin,ymax=ymax))
}
ci_intervals <- function(x) {
m <- mean(x, na.rm=TRUE)
sem <-sd(x, na.rm=TRUE)/sqrt(sum(!is.na(x)))
ymin<-m-1.96*sem
ymax<-m+1.96*sem
return(c(y=m,ymin=ymin,ymax=ymax))
}
## Define Wes Anderson colour scheme
budapest = c("#733080","#F4BAC8","#A40607","#7288B9","#F0C595",'#7294d4',"#e6a0c4", "#8896FF")
#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%
#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%
# Prepare DF
##################################################################
df <- data.frame(matrix(ncol = 6, nrow = 4810 + 4980 + 5000))
x <- c("country", "id", "name", "skills", "wage", "summary")
colnames(df) <- x
## Read JSON
df_json_1 <- RJSONIO::fromJSON("200923_freelancer_global_5000.JSON")
df_json_2 <- RJSONIO::fromJSON("201202_freelancer_global_5000.JSON")
df_json_3 <- RJSONIO::fromJSON("210104_freelancer_global_5000.JSON")
## Attribute JSON to DF
df$country <- c(df_json_1$country, df_json_2$country, df_json_3$country)
df$id <- c(df_json_1$id, df_json_2$id, df_json_3$id)
df$name<- c(df_json_1$name, df_json_2$name, df_json_3$name)
df$skills <- c(df_json_1$skills, df_json_2$skills, df_json_3$skills)
df$wage <- c(df_json_1$wage, df_json_2$wage, df_json_3$wage)
df$summary <- c(df_json_1$summary, df_json_2$summary, df_json_3$summary)
df$date <- c(rep("200903",4810), rep("201202",4980), rep("210104",5000))
#str_split(df$summary,"earned")[1]
## Clean Vars
df$skills <- gsub("\\)","",gsub("c\\(","",gsub('\\"',"",df$skills)))
df$country <- substr(df$country,2,100)
df$wage <- as.numeric(substr(gsub(" /hr","",df$wage),2,10))
## Add Vars
### Strings are different for December 2020
df$firstname <- ifelse(df$date == "200903", unlist(lapply(strsplit(df$name, " "), `[`, 1)),
unlist(lapply(strsplit(str_sub(df$name,10,100), " "), `[`, 1)))
### Add variable for past earnings
df$earned <- as.numeric(gsub("earned","",gsub("k","000",gsub("\\+","",gsub("\\$","",substr(df$summary,15,30))))))
# Store prepared file
#save(df, file="cross_skilling.rda")
#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%
# Find relevant AI skills
##################################################################
## Select only profiles that advertise "AI work" and un-nest skill tags
df_skills <- df %>% filter(str_detect(skills,"Artificial Intelligence") == TRUE) %>%
mutate(tag = strsplit(as.character(skills), ", ")) %>%
unnest(tag) %>% dplyr::select("id","tag")
## Calculate frequency of AI skills
df_skills <- df_skills %>% group_by(tag) %>% dplyr::summarise(N = n())
## Present AI skill tags as Wordcloud
df_skills %>% filter(tag != "Artificial Intelligence" & N > 1) %>%
ggplot(aes(label = tag, size = N*10)) + geom_text_wordcloud() + scale_size_area(max_size = 15) + theme_minimal()
ai_skills <- (df_skills %>% filter(tag != "Artificial Intelligence" & N > 1))$tag
out <- as.data.frame(ai_skills)
View(out)
View(df_skills)
# Save list of AI relevant tags
write.csv(df_skills, "freelance_ai_tags.csv", row.names=FALSE)
setwd("~/Fabian GDrive/Projects/Research Projects/OII/OLO/Worker Map")
#%#%#%#%#%#%#%#%#%#%#%#%%#%#%#%
# Read Gender Data
#%#%#%#%#%#%#%#%#%#%#%#%%#%#%#%
load("worker_gender.rda")
View(df_gender)
View(df_gender)
unique(df_gender$Occupation)
pph_sample <- read_excel("210224_pph_India_sample.xlsx")
View(pph_sample)
View(df_gender)
View(pph_sample)
View(df_gender)
View(df_gender)
View(pph_sample)
pph_sample <- pph_sample %>% group_by(Occupation, gender) %>% summarise(count = n())
View(pph_sample)
pph_sample <- read_excel("210224_pph_India_sample.xlsx")
pph_sample <- pph_sample %>% group_by(country, Occupation, gender) %>% summarise(count = n())
View(pph_sample)
View(df_gender)
pph_sample <- read_excel("210224_pph_India_sample.xlsx")
pph_sample <- pph_sample %>% group_by(country, Occupation, gender) %>% summarise(count2 = n())
df_gender <- left_join(df_gender,pph_sample)
View(df_gender)
df_gender <- df_gender %>% mutate(count = count + count2)
View(df_gender)
pph_sample <- read_excel("210224_pph_India_sample.xlsx")
#%#%#%#%#%#%#%#%#%#%#%#%%#%#%#%
# Read Gender Data
#%#%#%#%#%#%#%#%#%#%#%#%%#%#%#%
load("worker_gender.rda")
pph_sample <- read_excel("210224_pph_India_sample.xlsx")
pph_sample <- pph_sample %>% group_by(country, Occupation, gender) %>% summarise(count2 = n())
df_gender <- left_join(df_gender,pph_sample)
df_gender <- df_gender %>% mutate(count = count + count2, rm.na = T)
View(df_gender)
#%#%#%#%#%#%#%#%#%#%#%#%%#%#%#%
# Read Gender Data
#%#%#%#%#%#%#%#%#%#%#%#%%#%#%#%
load("worker_gender.rda")
pph_sample <- read_excel("210224_pph_India_sample.xlsx")
pph_sample <- pph_sample %>% group_by(country, Occupation, gender) %>% summarise(n = n())
df_gender <- left_join(df_gender,pph_sample)
df_gender <- df_gender %>% mutate(count = sum(count, n, na.rm = TRUE))
View(df_gender)
#%#%#%#%#%#%#%#%#%#%#%#%%#%#%#%
# Read Gender Data
#%#%#%#%#%#%#%#%#%#%#%#%%#%#%#%
load("worker_gender.rda")
pph_sample <- read_excel("210224_pph_India_sample.xlsx")
pph_sample <- pph_sample %>% group_by(country, Occupation, gender) %>% summarise(n = n())
df_gender <- left_join(df_gender,pph_sample)
df_gender <- df_gender %>% mutate(count = count + n, na.rm = TRUE)
View(df_gender)
#%#%#%#%#%#%#%#%#%#%#%#%%#%#%#%
# Read Gender Data
#%#%#%#%#%#%#%#%#%#%#%#%%#%#%#%
load("worker_gender.rda")
pph_sample <- read_excel("210224_pph_India_sample.xlsx")
pph_sample <- pph_sample %>% group_by(country, Occupation, gender) %>% summarise(n = n())
df_gender <- left_join(df_gender,pph_sample)
df_gender <- df_gender %>% rowwise() %>% mutate(count = sum(count, n, na.rm = TRUE))
View(df_gender)
shiny::runApp()
runApp()
runApp()
runApp()
View(df_gender)
df <- df_gender %>% filter(!is.na(gender)) %>%
group_by(country, gender) %>% dplyr::mutate(total_share = sum(count)) %>%
group_by(country) %>% dplyr::mutate(total_share = round(total_share/sum(count)*100,1))
View(df)
runApp()
runApp()
runApp()
runApp()
runApp()
runApp('~/Fabian GDrive/Projects/Research Projects/OII/OLO/OLI2020')
shiny::runApp()
